{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "AudioClassification1D.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ARBasharat/AudioClassification/blob/master/AudioClassification1D_wo_Augmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pKd4WHgN_2I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import random\n",
        "import librosa\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4rpOw4gziwf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "train = np.load(\"drive/My Drive/AudioClassification/audio_train.npy\").astype('float32')\n",
        "test = np.load(\"drive/My Drive/AudioClassification/audio_test.npy\").astype('float32')\n",
        "train_labels_df = pd.read_csv(\"drive/My Drive/AudioClassification/labels_train.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaQAD_G-On32",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels = train_labels_df.to_numpy()[:,1]\n",
        "labels_categorical = keras.utils.to_categorical(train_labels)\n",
        "\n",
        "X_train_original, X_val_original, y_train_original, y_val = train_test_split(train, \n",
        "                          labels_categorical, test_size=0.20, random_state=42)\n",
        "\n",
        "print(\"Training Data:\", X_train_original.shape)\n",
        "print(\"Training Labels:\", y_train_original.shape)\n",
        "print(\"Validation Data:\", X_val_original.shape)\n",
        "print(\"Validation Labels:\", y_val.shape)\n",
        "print(\"Testing Data:\", test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTosG_h9PJzp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## We switch between white and normal noise randomly\n",
        "\n",
        "def add_white_noise(data, rate = 0.05):\n",
        "  data_with_white_noise = data + rate * np.random.randn(len(data))\n",
        "  return data_with_white_noise\n",
        "\n",
        "'''\n",
        "Noise addition using normal distribution with mean = 0 and std =1\n",
        "Permissible noise factor value = x > 0.004\n",
        "'''\n",
        "def add_normal_distributed_noise(data, rate = 0.09, sr = 30000):\n",
        "  data_with_noramlized_noise = data + rate * np.random.normal(0, 1, len(data))\n",
        "  return data_with_noramlized_noise\n",
        "\n",
        "'''\n",
        "Time Shifting\n",
        "Permissible factor values = sr/10\n",
        "'''\n",
        "def add_time_shift(data, sr = 30000):\n",
        "  data_with_time_shift = np.roll(data, int(sr/10))\n",
        "  return data_with_time_shift\n",
        "\n",
        "'''\n",
        "Pitch shifting\n",
        "Permissible factor values = -5 <= x <= 5\n",
        "'''\n",
        "def add_pitch_shift(data, sr = 30000, steps = -7):\n",
        "  data_with_pitch_shift = librosa.effects.pitch_shift(data, sr, n_steps = steps)\n",
        "  return data_with_pitch_shift"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVkqhn9iOkRD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get augmented_training data equal to size of real data\n",
        "def get_augmented_data_two_times(X_train_original, y_train_original):\n",
        "  new_data = []\n",
        "  new_labels = []\n",
        "  for i in range(0, len(X_train_original)):\n",
        "    data = X_train_original[i]\n",
        "    label = y_train_original[i]\n",
        "    choice = random.choice([1, 2, 3, 4]) ## Used for selecting between white noise and normalized noise\n",
        "    ## get augmented data\n",
        "    new_data.append(data)\n",
        "    if choice == 1:\n",
        "      new_data.append(add_white_noise(data))\n",
        "    elif choice == 2:\n",
        "      new_data.append(add_normal_distributed_noise(data))\n",
        "    elif choice == 3:\n",
        "      new_data.append(add_time_shift(data))\n",
        "    elif choice == 4:\n",
        "      new_data.append(add_pitch_shift(data))\n",
        "    ## get labels\n",
        "    new_labels.append(label)\n",
        "    new_labels.append(label)\n",
        "\n",
        "  ## Get augmented train data and labels\n",
        "  train_data = np.array(new_data)\n",
        "  y_train = np.array(new_labels)\n",
        "  return train_data, y_train\n",
        "\n",
        "train_data, y_train = get_augmented_data_two_times(X_train_original, y_train_original)\n",
        "print(train_data.shape, y_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0_t6ZvmW7cL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get training data without augmentation\n",
        "def get_data_2(X_train_original, y_train_original):\n",
        "  new_data = []\n",
        "  new_labels = []\n",
        "  for i in range(0, len(X_train_original)):\n",
        "    data = X_train_original[i]\n",
        "    label = y_train_original[i]\n",
        "    new_data.append(data)\n",
        "    new_labels.append(label)\n",
        "  train_data = np.array(new_data)\n",
        "  y_train = np.array(new_labels)\n",
        "  return train_data, y_train\n",
        "\n",
        "#train_data, y_train = get_data_2(X_train_original, y_train_original)\n",
        "#print(train_data.shape, y_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bl4yARVXTCpx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data /= train_data.max()\n",
        "X_val_original /= X_val_original.max()\n",
        "test /= test.max()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wTLj5JIPouL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = train_data.reshape((train_data.shape[0], train_data.shape[1], 1))\n",
        "X_val = X_val_original.reshape((X_val_original.shape[0], X_val_original.shape[1], 1))\n",
        "X_test = test.reshape((test.shape[0], test.shape[1], 1))\n",
        "print(X_train.shape, X_val.shape, X_test.shape, y_train.shape, y_val.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bu8hKb8E0rBH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Base Model Architecture \n",
        "def getBaseModel():\n",
        "  model = models.Sequential()\n",
        "  model.add(layers.Conv1D(32, 3, activation='relu', input_shape=(30000, 1)))\n",
        "  model.add(layers.MaxPooling1D(2))\n",
        "  model.add(layers.Conv1D(64, 3, activation='relu'))\n",
        "  model.add(layers.MaxPooling1D(2))\n",
        "  model.add(layers.Conv1D(128, 3, activation='relu'))\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(128, activation='relu'))\n",
        "  model.add(layers.Dense(64, activation='relu'))\n",
        "  model.add(layers.Dense(10, activation='softmax'))\n",
        "  model.summary()\n",
        "  return model\n",
        "\n",
        "def get_model_2():\n",
        "  model = tf.keras.models.Sequential()\n",
        "  model.add(layers.Conv1D(32, kernel_size=3, activation='relu', \n",
        "                    input_shape=(30000, 1)))\n",
        "  model.add(layers.Dropout(0.25))\n",
        "  model.add(layers.Conv1D(48, kernel_size=3, activation='relu'))\n",
        "  model.add(layers.Conv1D(120, kernel_size=3, activation='relu'))\n",
        "  model.add(layers.MaxPooling1D(pool_size=2))\n",
        "  model.add(layers.Dropout(0.25))\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(128, activation='relu'))\n",
        "  model.add(layers.Dropout(0.25))\n",
        "  model.add(layers.Dense(64, activation='relu'))\n",
        "  model.add(layers.Dropout(0.4))\n",
        "  model.add(layers.Dense(10, activation='softmax'))\n",
        "  return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYVYzIIdN_2u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Compile and Train Model with Early stopping\n",
        "def compileModel(model, optimizer = 'sgd', epochs = 10):\n",
        "  earlyStopping = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
        "  \n",
        "  model.compile(optimizer=optimizer,\n",
        "          loss=tf.keras.losses.categorical_crossentropy,\n",
        "          metrics=['accuracy'])\n",
        "  \n",
        "  history = model.fit(X_train, y_train, epochs=epochs, verbose=2, batch_size=64,\n",
        "          validation_data=(X_val, y_val), callbacks=earlyStopping)\n",
        "  \n",
        "  return history\n",
        "\n",
        "## Plot Training History\n",
        "def plotTrainingAccuracy(history):\n",
        "  plt.figure()\n",
        "  plt.plot(history.history['accuracy'], label='training_accuracy')\n",
        "  plt.plot(history.history['val_accuracy'], label = 'validation_accuracy')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.legend(loc='upper left')\n",
        "  plt.show()\n",
        "  plt.close()\n",
        "\n",
        "def plotTrainingLoss(history):\n",
        "  plt.figure()\n",
        "  plt.plot(history.history['loss'], label='training_loss')\n",
        "  plt.plot(history.history['val_loss'], label = 'validation_loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend(loc='upper left')\n",
        "  plt.show()\n",
        "  plt.close()\n",
        "\n",
        "## Evaluate the model\n",
        "def predictModel(model, test):\n",
        "  return model.predict(test, verbose=0)\n",
        "  \n",
        "\n",
        "## Evaluate the model\n",
        "def evaluateModel(model, X_test, y_test):\n",
        "  test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "  print(\"\\n ### Performance of Test Data ###\")\n",
        "  print(\"Test Accuracy: \", test_acc)\n",
        "  print(\"Test Loss: \", test_loss, \"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAlaXn85N_2x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = get_model_2()\n",
        "history = compileModel(model, optimizer = 'adam', epochs = 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZI7UI22NN_23",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plotTrainingAccuracy(history)\n",
        "plotTrainingLoss(history)\n",
        "evaluateModel(model, X_val, y_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoNqor6aAjWU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = predictModel(model, test_data)\n",
        "preds = []\n",
        "for p in predictions:\n",
        "  preds.append(np.argmax(p))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwpOE_YaJUfu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.DataFrame(preds).to_csv(\"submission.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}